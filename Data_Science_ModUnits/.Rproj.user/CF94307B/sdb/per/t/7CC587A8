{
    "contents" : "# David - represents the task\n# Pepper - represents the actions\n\n# David: Ok Pepper here is some data\ndata<-read.csv(\"C:/Users/dwoo57/Google Drive/Career/Data Mining Competitions/Kaggle/Walmart - Inventory and weather prediction/Experiments/Beta/Data_Collection/Store_31_item_9_2012_2014.csv\")\n\n# David: Ok Pepper, what do you see?\nstr(data)\n\n# David: Make the orig_date as date <<< This could make it into JSON\ndata$orig_date<-as.Date(data$orig_date,\"%m/%d/%Y\")\nstr(data)\nsummary(data)\n\ncolnames(data)[4]<-\"unitsP\"\n\nstr(data)\n\n# HYPOTHESIS: Below are the hypothesis to test:\n\n#Pepper: What type of problem is this?\n#David: This is a time series forecasting problem. Oh ya and this is a retail problem\n#Pepper: Ah retail...that gives me some hints as well\n\n#Pepper: Got it...hmm let me check my corpus to see what I should test for....\n\"Corpus:\nSeasonality: Monthly, Weekly,Daily\nTrend: Year over year\nHolidays:\nAutocorrelation\n  - between recent days\n  - between recent week\"\n#Pepper: This is what my corpus says\n\n#David: Pepper this is cool and love the charts...oh ya what are our hypothesis?\n\n\"Pepper: Ah good point. Here they are\n1) Pay week (Complete!)\n  3) If i shop on Sat i prob wont shop on Sun\n  4) If I shop on Fri, i prob wont shop on Sat\n2) Non pay week (Complete!)\n  3) If i shop on Sat i prob wont shop on Sun\n  4) If I shop on Fri, i prob wont shop on Sat\n5) Mid week top up\n6) Prior week shopping compared to this week\"\n\n# Numerical to numerical - we have this test - we are using linear regression/anova to test linear correlation\n# Categorical to Numerical - #\n\n# Can use ANOVA if have more than two levels for an independent variables\n# for each level can we tell which is significant?\n\nlibrary(sqldf)\n\n# This is still good. This is a module can be generalized. Testing for significance. \n#Can we use the same but now test for fri_delta\n#Can it take a JSON?\n\n#SCENARIO: say we want to look at the delta between fri and sat vs sat and sun\n\n# 1. Data time........start with what data to use? or which features to create?\n# Filters\n# New Features\n\n#How to generalize this? Can we deconstruct this?\n\n# Features : a.orig_date, a.Weeknum_4week, units_Sun, units_Sat, units_Fri\n# Filters:\n# Joins: \n\n#filters = \"and a.Year = 2012 and a.dayofweek= 7\"\nfilters = \"and a.Year = 2012\"\nFeatures_list = \"SELECT a.orig_date,b.orig_date,a.dayofweek,a.Weeknum_4week ,b.dayofweek as dayofweek_prev, a.unitsP,b.unitsP as units_prev\"\n\nQuery = \"SELECT a.orig_date,a.dayofweek,a.Weeknum_4week,\n              b.orig_date,b.dayofweek as dayofweek_prev,\n              c.orig_date,c.dayofweek as dayofweek_prev,\n              a.unitsP as units_Sun,b.unitsP as units_Sat,c.unitsP as units_Fri,\n              c.unitsP - b.unitsP as dlt_Fri_Sat, b.unitsP - a.unitsP as dlt_Sat_Sun\n              FROM data a , data b, data c\n              where a.dayofweek = b.dayofweek + 1\n              and a.dayofweek = c.dayofweek + 2\n              and a.Year = b.Year\n              and a.Weeknum = b.Weeknum\n              and a.Year = c.Year\n              and a.Weeknum = c.Weeknum\n              \"\nFinal_query<-paste(Query,filters,sep=\"\")\n\nQuery = \"SELECT a.orig_date,a.dayofweek,a.Weeknum_4week,\n              b.orig_date,b.dayofweek as dayofweek_prev,\n              c.orig_date,c.dayofweek as dayofweek_prev,\n              a.unitsP as units_Sun,b.unitsP as units_Sat,c.unitsP as units_Fri,\n              c.unitsP - b.unitsP as dlt_Fri_Sat, b.unitsP - a.unitsP as dlt_Sat_Sun\n              FROM data a , data b, data c\n              where a.dayofweek = b.dayofweek + 1\n              and a.dayofweek = c.dayofweek + 2\n              and a.Year = b.Year\n              and a.Weeknum = b.Weeknum\n              and a.Year = c.Year\n              and a.Weeknum = c.Weeknum\n              and a.Year = 2012\n              and a.dayofweek= 7\"\n\ndata_2012_weekend_delta <- sqldf(gsub(\"\\n\", \"\", Final_query))\n\n\n#1b. Let's check the data\nstr(data_2012_weekend_delta)\nhead(data_2012_weekend_delta)\nsummary(data_2012_weekend_delta)\n\n\ndata_cleaned<-data_2012_weekend_delta\nsummary(data_cleaned)\n\ndata_cleaned$dayofweek<-factor(data_cleaned$dayofweek)\ndata_cleaned <- na.omit(data_cleaned)\n\n\n#Maybe we need some indicators...need some objective measures.\n#i.e linear regression or testing for correlation\n\nlibrary(plyr)\nmodels <- dlply(data_cleaned, \"Weeknum_4week\", function(data_cleaned) {\n  lm(data_cleaned$dlt_Sat_Sun ~ data_cleaned$dlt_Fri_Sat, data = data_cleaned)} )\n\n\n# this will help us get the p values\nanovas <- llply(models, anova)\n\nmodels\nanovas\n\n# So interesting...This\n\n# For delta: week 0 and 1 are significant. Week 3 almsot significant\n# Should we plot it? Is this similar for 2013?\n# For 2013: onyl week 1 \n# For 2014: Looks like strong correlation\n\n# Also are we grouping weeks? This is good, it is becoming more and more generalizable...\n\nrequire (\"lattice\")\n# how to order this?\n# Have to make it a factor as well\n# Plotting definetely helps\nstr(data)\ndata$Weeknum_4week<-factor(data$Weeknum_4week)\nxyplot(data_cleaned$dlt_Sat_Sun ~ data_cleaned$dlt_Fri_Sat | Weeknum_4week, data, pch= 2,as.table=TRUE,strip=strip.custom(strip.names=1),\n       type = c(\"p\", \"r\"), col.line = \"darkorange\", lwd = 4)\n\n# Can we now explore the features\n\n# Say we are predicting Sun. can it learn from the features and store the results\n\n# Store range and some generalizable index?\n\n#Pepper/Olivia\n# David: Can we try storing our results, so we can review over time\n# Pepper: Ok how should I? Maybe this is more a nice to have\n\n# Maybe build the capabilities of testing first....\n\n#so built another capabilities - cat on numerical effect. Then just use visual effect\n# use anova to see if they are significant. If there are significant then just inspect visually.\n\nfit<-aov(data_cleaned$units_Fri ~ data_cleaned$Weeknum_4week,data = data_cleaned)\n\n# Maybe for this we start with day of week. Know that this is significant. Then after this refine?\nfit<-aov(data_cleaned$units_Fri ~ data_cleaned$dayofweek + data_cleaned$Weeknum_4week ,data = data_cleaned)\nsummary(fit)\nplot(fit) # diagnostic plots\n\n#So interesting weeknum has effect on Sun\n\n#David: Pepper...can we put it all together...can we help find relationships...we didnt see before?\n# Pepper: Maybe a catersian products or matrix of features\n\"\nGoal is to predict Sunday:\n\nMaybe we can form matrix based on their values types\n\nCat on Numerical:\nPayweek vs Sun. Completed.\nMonth vs Sun. Maybe try this first.\nHoliday/Non-Holiday/Prev-Holiday Weeks vs Sun. This may be interesting\n\n\nNumerical on Numerical:\nH1A: Delta Fri-Sat vs Delta Sat-Sun : Abs vs Percentage. Completed\nH1B: Sum of weekends vs Sun (within week: Weekdays vs Weekends)\nH1C: Last Sun vs This Sun (week: Last week vs this week). Try this\n\"\n\n\"\nCan we build this into modules\n\"\n\n# 1.Load the data\n\ndata<-read.csv(\"C:/Users/dwoo57/Google Drive/Career/Data Mining Competitions/Kaggle/Walmart - Inventory and weather prediction/Experiments/Beta/Data_Collection/Store_31_item_9_2012_2014.csv\")\n\n# 2.Any initial feature transformation\ndata$orig_date<-as.Date(data$orig_date,\"%m/%d/%Y\")\n\nstr(data)\nsummary(data)\n\n#3. Now create new features\n\nlibrary(sqldf)\n\n# Below is for week prior: H1C\n\nfeatures_list = \"SELECT a.orig_date,a.dayofweek,a.Weeknum_4week,\n                  a.units, b.units as units_pr_week\"\ntables = \" FROM data a , data b\"\njoins = \" where a.dayofweek = b.dayofweek\n        and a.Year = b.Year\n        and a.Weeknum = b.Weeknum + 1\"\nfilters = \" and a.Year = 2012 and a.dayofweek= 7\"\n\n# Below is for week prior: H1A\n\nfeatures_list = \"SELECT a.orig_date,a.dayofweek,a.Weeknum_4week,\n                  c.units - b.units as dlt_Fri_Sat, b.units - a.units as units_predict\"\ntables = \" FROM data a , data b, data c\"\njoins = \" where a.dayofweek = b.dayofweek + 1\n              and a.dayofweek = c.dayofweek + 2\n              and a.Year = b.Year\n              and a.Weeknum = b.Weeknum\n              and a.Year = c.Year\n              and a.Weeknum = c.Weeknum\"\nfilters = \" and a.Year = 2012 and a.dayofweek= 7\"\n\nfinal_query<-paste(features_list,tables,joins,filters,sep=\" \")\n\ndata_cleaned <- sqldf(gsub(\"\\n\", \"\", final_query))\n\n#4. Now do the numerical analysis\nstr(data_cleaned)\n\n\nlibrary(plyr)\nmodels <- dlply(data_cleaned, \"Weeknum_4week\", function(data_cleaned) {\n  lm(units_predict ~ dlt_Fri_Sat, data = data_cleaned)} )\n\n\n# this will help us get the p values\nanovas <- llply(models, anova)\n\nmodels\nanovas\n\n#5. Store the results\nresults =c(\"units_pr_week\",\"prior\",0.1532,0.1989)\nresults2 =c(\"units_pr_week\",\"prior\",0.1532,0.1989)\n\nresults =c(\"dlt_Fri_Sat\",\"week0\",0.001681,0.7592)\nresults2 =c(\"dlt_Fri_Sat\",\"week1\",0.02658,-0.8942)\nresults3 =c(\"dlt_Fri_Sat\",\"week2\",0.5541,-0.174)\nresults4 =c(\"dlt_Fri_Sat\",\"week3\",0.06733,-0.6888)\n\nIV_list = list(results)\nIV_list[length(IV_list)+1] <-list(results)  \nIV_list[length(IV_list)+1] <-list(results2)  \nIV_list[length(IV_list)+1] <-list(results3)  \nIV_list[length(IV_list)+1] <-list(results4) \n\nIV_list\n\n#this only has two levels of treatment. Can still use anova? For now assume, yes, two ore more\n\n# Can we store this value, the p-value\n\n\"Ultimately want a table like\n\nfor numerical to numerical, may not have levels\n\nX-variable(name)|X-variable levels | P-value(how significant)|Coefficient(Impact/how much it changes it by)\n\n\"\n\n# With each interation we can generalize\n",
    "created" : 1435069766026.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1469000361",
    "id" : "7CC587A8",
    "lastKnownWriteTime" : 1434639337,
    "path" : "C:/Users/dwoo57/Google Drive/Knowledge Base/R Scripts/Data_Science_ModUnits/OliviaIO_Curiosity_Module_Numerical_Numerical_Test_v1.R",
    "project_path" : "OliviaIO_Curiosity_Module_Numerical_Numerical_Test_v1.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}