Title
========================================================

This is an R Markdown document. Markdown is a simple formatting syntax for authoring web pages (click the **Help** toolbar button for more details on using R Markdown).

When you click the **Knit HTML** button a web page will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

**Objective**:

Framework:

A) eq: input -> model -> output

B) Reduce it to the lowest common unit

C) Ask why? Why is this important?

D) Generalization is a key concept. Random sampling....fewer + broad rules vs many + niche rules

1. Context.Domain: Walmart sales. (Retail, lower income group, Arkansas hq, weekly sales revenue)

1. Work backwards. What is the output?

2. Output: 9 months of weekly sales (revenue, not inventory, assume price is consistent). Granularity: week

3. Model:

3a.  What are the simplifying equations: What is it made of? What would drive it? Think of the who? Who is the user? Who is the decision maker? In this case, the user is the grocery shopper...

3b.  Week seasonality: Pay periods vs non pay periods (bi-weekly, pay check to pay check). Food stamps.

3c.  Month seasonality: Based on seasons, winter vs summer (some products are weather sensitive)

3d.  Holiday seasonaity: Type of holiday( xmas vs superbowl), holiday occuring on weekday vs a weekend

3e.  External factors: Promo effects

3f.  Trends: Grow customer base ( more shops, more customer base - from unemployed, other retailers). Grow engagement ( more spend from current customers - promos) 


**Exploration/Hypothesis Generation**:

1. Hypothesis: Seasonality + Trend = Sales

a) Seasonality is similar year on year as seen on the charts

b) Trend: 2011 ( 2nd half) -> 2010 + x , 2012 ( first half) -> 2010 + X. Is trend inc/dec/stop? What drives trend?


```{r}
summary(cars)
```

You can also embed plots, for example:

```{r fig.width=7, fig.height=6}
plot(cars)
```

like the idea of calling it a sample, meaning that it's not the full population so we want to intepret abt the population
```{r}
sample<-read.csv('C:/Users/dwoo57/Google Drive/Career/Data Mining Competitions/Kaggle/Walmart - Inventory and weather prediction/Experiments/Gamma/Exp_A/Dept92_All_stores.csv')
sample$Date<-as.Date(sample$Date,"%m/%d/%Y")
str(sample)

sample2<-read.csv('C:/Users/dwoo57/Google Drive/Career/Data Mining Competitions/Kaggle/Walmart - Inventory and weather prediction/Experiments/Gamma/Exp_A/Dept92_All_stores_V2.csv')
sample2$Date<-as.Date(sample2$Date,"%m/%d/%Y")
str(sample2)
```

knit may be abit slow for modeling etc. Good to have for documentation but may want to keep both codes open
Based on the below
```{r}
library(plyr)
library(lattice)  #xyplot
library(latticeExtra)  #layer_, panel.xblocks
library(gridExtra)  #grid.arrange
library(RColorBrewer)  #brewer.pal
library(ggplot2)

sample.new<-ddply(sample, .(Date,Weeknum,Year,IsHoliday),summarise,Weekly_Sales = sum(Weekly_Sales))
str(sample.new)
ddply(sample, .(Year),summarise,Weekly_Sales = sum(Weekly_Sales))

sample2.new<-ddply(sample2, .(Date,Weeknum_mod,Year,IsHoliday),summarise,Weekly_Sales = sum(Weekly_Sales))
str(sample.new)
ddply(sample2, .(Year),summarise,Weekly_Sales = sum(Weekly_Sales))
```


```{r fig.width=20, fig.height=6}
ggplot(sample.new, aes(Weeknum,Weekly_Sales)) + 
  geom_line( aes(colour = factor(Year) ),size = 1)  + 
  geom_point( aes(color = factor(IsHoliday)),size = 3.5)
```


Transformation:

1. Aligning the weeks for comparison. Why it matter? Seasonality is consistent year on year, even with promos.

2. So looks like next area is understanding the split. in 2011, 2nd half when it started splitting. 

2a.  Consider using average - want to generalize across stores. Also, when looking at stores can we group them. High level then low level

```{r fig.width=20, fig.height=6}
ggplot(sample2.new, aes(Weeknum_mod,Weekly_Sales)) + 
  geom_line( aes(colour = factor(Year) ),size = 1)  + 
  geom_point( aes(color = factor(IsHoliday)),size = 3.5)
```


Thoughts:

1. In 2011, determine when the split ocurred - what are the external drivers? What causes this
2. Do we apply the same trend in 2012 for the first half?
3. Can we generalize across stores? High level grouping?

Next steps:
Q: Since trends are all increasing, what are explanatory variables that can explain it? i.e unemployment rate?

1. For store type A, take a random sample and plot difference year on year

a) Steps calculate year on year difference for the same store (done)
b) now take random sample of stores

str(sample2)

#First get a single store
sample2.store39<-subset(sample2, Store == 39)
str(sample2.store39)

#next how does the data look like
head(sample2.store39)
# need to match where year = year + 1 and weeknum = weeknum
install.packages("dplyr")
library(dplyr)

sample.tbl<-tbl_df(sample2.store39)

head(sample.tbl)
str(sample.tbl)
summary(sample.tbl)

sample.tbl %>
require(plyr)
library(quantmod)


subset.store39<-subset(sample2.store39, select =c('Date', 'Weekly_Sales','Weeknum_mod','Year'))
str(subset.store39)
ds_test$Store
#diff uses the consective arguments

#ddply(subset.store39, .(Weeknum_mod) , mutate, yoy = c(NA,diff(Weekly_Sales)/Weekly_Sales ))

ds<-ddply(subset.store39, .(Weeknum_mod) , transform, yoy_per = Delt(Weekly_Sales), yoy = c(NA,diff(Weekly_Sales)) )

ds<-subset(ds, Year ==2011)

plot(ds$Weeknum_mod,ds$Delt.1.arithmetic, type ='l')


b) Second part random sample

set.seed(1234)
take <- sample(unique(sample2$Store), 10)

NROW(unique(sample2$Store))
ncol(unique(sample2$Store))

take

ds_test<-sample2[sample2$Store %in% take, ]

summary(ds_test)
ds_test$Store<-as.factor(ds_test$Store)
NROW(unique(ds_test$Store))

c) now calculate diff 

ds<-ddply(ds_test, .(Store,Weeknum_mod) , transform, yoy_per = Delt(Weekly_Sales), yoy = c(NA,diff(Weekly_Sales)) )
ds<-subset(ds, Year ==2011)

str(ds)

#initial plot
#what is out goal here...take a sample to see what is going on.
#what are the questions we are interested? If they are all similar then should be similar to the average?
#do we then just say that type A has this trend?
#oh we wanted to understand what the drivers where, how they correlate to explanatory variables?

library(ggplot2)
ggplot(ds, aes(Weeknum_mod,Delt.1.arithmetic)) + 
  geom_line( aes(colour = factor(Store) ),size = 1)  + 
  geom_point(size = 2)

#These are the next steps
#very hard to see
#unless we smooth it out to see what is going on
#what is the monthly average



